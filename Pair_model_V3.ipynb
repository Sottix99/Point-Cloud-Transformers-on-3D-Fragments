{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import special_ortho_group\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import miners, losses\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_GPU():\n",
    "    \"\"\" This function activates the gpu \n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(torch.cuda.get_device_name(0), \"is available and being used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU is not available, using CPU instead\") \n",
    "    return device  \n",
    "\n",
    "\n",
    "def center_in_origin(frag):\n",
    "    \"\"\" This function normalize each fragment in (0,1)\n",
    "    \"\"\"\n",
    "    min_vals, _ = torch.min(frag[:, 0:3], axis=0)\n",
    "    max_vals, _ = torch.max(frag[:, 0:3], axis=0)\n",
    "    frag[:, 0:3] = (frag[:, 0:3] - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    return frag\n",
    "    \n",
    "def normalize(batch):\n",
    "    \"\"\" This function apply center_in_origin() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(center_in_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor  \n",
    "\n",
    "\n",
    "\n",
    "def translate_to_origin(frag):\n",
    "    \"\"\" This function translate each fragment in the origin\n",
    "    \"\"\"\n",
    "    frag[:,:3] -= torch.mean(frag[:,:3]) \n",
    "    return frag\n",
    "\n",
    "def apply_translation(batch):\n",
    "    \"\"\" This function apply translate_to_origin() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(translate_to_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def random_rotation(frag):\n",
    "\n",
    "    randrot = (torch.rand(3)*360).tolist()\n",
    "    r = R.from_euler('zyx', randrot, degrees=True)\n",
    "    frag[:,:3] = torch.from_numpy(r.apply(frag[:,:3]))\n",
    "    frag[:,3:6] = torch.from_numpy(r.apply(frag[:,3:6]))\n",
    "    return frag\n",
    "\n",
    "def apply_randomrotations(batch):\n",
    "    \"\"\" This function apply random_rotation() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(random_rotation(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code form the repository of PCT https://github.com/qq456cvb/Point-Transformers\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    return torch.sum((src[:, :, None] - dst[:, None]) ** 2, dim=-1)\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)\n",
    "\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        distance = torch.min(distance, dist)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def sample_and_group(npoint, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint \n",
    "    \n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint]\n",
    "\n",
    "    new_xyz = index_points(xyz, fps_idx) \n",
    "    new_points = index_points(points, fps_idx)\n",
    "\n",
    "    dists = square_distance(new_xyz, xyz)  # B x npoint x N\n",
    "    idx = dists.argsort()[:, :, :nsample]  # B x npoint x K\n",
    "\n",
    "    grouped_points = index_points(points, idx)\n",
    "    grouped_points_norm = grouped_points - new_points.view(B, S, 1, -1)\n",
    "    new_points = torch.cat([grouped_points_norm, new_points.view(B, S, 1, -1).repeat(1, 1, nsample, 1)], dim=-1)\n",
    "    return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Local_op(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, s, d = x.size()  # torch.Size([32, 512, 32, 6]) \n",
    "        x = x.permute(0, 1, 3, 2)\n",
    "        x = x.reshape(-1, d, s)\n",
    "        batch_size, _, N = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = x.reshape(b, n, -1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SA_Layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n",
    "        x = x + x_r\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class StackedAttention(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer(channels)\n",
    "        self.sa2 = SA_Layer(channels)\n",
    "        self.sa3 = SA_Layer(channels)\n",
    "        self.sa4 = SA_Layer(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SA_Layer_classic(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x_r)))\n",
    "        \n",
    "        return x_r\n",
    "\n",
    "\n",
    "class StackedAttention_classic(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer_classic(channels)\n",
    "        self.sa2 = SA_Layer_classic(channels)\n",
    "        self.sa3 = SA_Layer_classic(channels)\n",
    "        self.sa4 = SA_Layer_classic(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        d_points = 7 # we have 7 features for each point\n",
    "        self.conv1 = nn.Conv1d(d_points, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.gather_local_0 = Local_op(in_channels=128, out_channels=128)\n",
    "        self.gather_local_1 = Local_op(in_channels=256, out_channels=256)\n",
    "        self.pt_last = StackedAttention()###############################################################\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm1d(1024),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xyz = x[..., :3]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        batch_size, _, _ = x.size()\n",
    "        x= x.double()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = x.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=512, nsample=32, xyz=xyz, points=x)         \n",
    "        feature_0 = self.gather_local_0(new_feature)\n",
    "        feature = feature_0.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=256, nsample=32, xyz=new_xyz, points=feature) \n",
    "        feature_1 = self.gather_local_1(new_feature)\n",
    "        \n",
    "        x = self.pt_last(feature_1)\n",
    "        x = torch.cat([x, feature_1], dim=1)\n",
    "        x = self.conv_fuse(x)\n",
    "        x = torch.max(x, 2)[0] # Returns the maximum value of all elements in the input tensor. (2 elementes for each vector)\n",
    "        x = x.view(batch_size, -1) # Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "train = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\train_pair_dataset_REG.pt\")\n",
    "val = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\val_pair_dataset_REG.pt\")\n",
    "test = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\test_pair_dataset_REG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions to remove (Train): [2, 14, 20, 22, 28, 30, 31, 35, 36, 39, 71, 78, 87, 91, 95, 109, 136, 148, 163, 167, 192, 197, 205, 209, 215, 217, 218, 222, 228, 241, 255, 261, 263, 265, 273, 284, 300, 308, 318, 337, 344, 346, 353, 361, 364, 369, 398, 420, 423, 427, 431, 433, 468, 469, 471, 474, 489, 494, 496, 507, 513, 516, 517, 538, 547, 551, 564, 577, 591, 595, 597, 600, 607, 613, 617, 633, 635, 644, 651, 652, 660, 664, 675, 689, 694, 699, 700, 707, 711, 721, 731, 735, 754, 757, 758, 763, 768, 771, 776, 783, 789, 813, 818, 831, 834, 837, 841, 844, 846, 874, 879, 896, 909, 917, 931, 943, 971, 977, 979, 988, 991, 994, 996, 999, 1042, 1045, 1050, 1057, 1077, 1078, 1079, 1084, 1100, 1109, 1118, 1126, 1127, 1129, 1130, 1131, 1143, 1150, 1156, 1188, 1217, 1219, 1227, 1254, 1274, 1284, 1290, 1295, 1299, 1316, 1324, 1334, 1336, 1337, 1347, 1353, 1356, 1390, 1392, 1412, 1418, 1460, 1463, 1466, 1469, 1474, 1483, 1489, 1498, 1499, 1504, 1505, 1507, 1514]\n",
      "Positions to remove (Val): [6, 12, 13, 22, 24, 31, 65, 70, 77, 94, 105, 118, 125, 137, 145, 147, 157, 162, 169, 173, 177, 180, 187, 192, 196, 216, 219, 241, 255, 281, 293, 294, 300, 301, 308]\n"
     ]
    }
   ],
   "source": [
    "# let's find the largest clusters\n",
    "\n",
    "count = 0\n",
    "indices = []\n",
    "count_val = 0\n",
    "indices_val = []\n",
    "\n",
    "for i in range(0, 1526):\n",
    "    if train[i][0].shape[0] > 70:\n",
    "        count += 1\n",
    "        indices.append(i)\n",
    "\n",
    "for i in range(0, val.shape[0]):\n",
    "    if val[i][0].shape[0] > 70:\n",
    "        count_val += 1\n",
    "        indices_val.append(i)\n",
    "\n",
    "print(\"Positions to remove (Train):\", indices)\n",
    "print(\"Positions to remove (Val):\", indices_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are removing the largest clusters for computational reasons\n",
    "mask = torch.ones(train.shape[0], dtype=torch.bool)\n",
    "mask[indices] = False\n",
    "filtered_tensor = train[mask]\n",
    "train = filtered_tensor\n",
    "\n",
    "mask_val = torch.ones(val.shape[0], dtype=torch.bool)\n",
    "mask_val[indices_val] = False\n",
    "filtered_tensor_val = val[mask_val]\n",
    "val = filtered_tensor_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_test = 0\n",
    "indices_test = []\n",
    "\n",
    "for i in range(0, 327):\n",
    "    if test[i][0].shape[0] > 70:\n",
    "        count_test += 1\n",
    "        indices_test.append(i)\n",
    "mask_test = torch.ones(test.shape[0], dtype=torch.bool)\n",
    "mask_test[indices_test] = False\n",
    "filtered_tensor_test = test[mask_test]\n",
    "test= filtered_tensor_test     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348, 2)\n",
      "(292, 2)\n",
      "(289, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjmatrix_into_y(adj_mat):\n",
    "\n",
    "    \"\"\" This function maps the adj_matrix into a vector (leverage the matrix symmetry to save computations)\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    \n",
    "    # Discover the number of fragments\n",
    "    n_frags = len(adj_mat[0])\n",
    "    \n",
    "    for j in range(0, n_frags - 1):\n",
    "        init = j + 1\n",
    "        for k in range(init, n_frags):\n",
    "            \n",
    "            labels.append(adj_mat[j][k])\n",
    "    \n",
    "    return  labels\n",
    "\n",
    "def max_the1_v (vector):\n",
    "\n",
    "    \"\"\"  This function outputs a vector containing the positions of fragment pairs to extract in order to ensure generating the maximum possible number of balanced pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    how_many_ones = 0\n",
    "    how_many_zeroes = 0\n",
    "\n",
    "    positions_0 = []\n",
    "    positions_1 = []\n",
    " \n",
    "\n",
    "    for i, elemento in enumerate(vector):\n",
    "        if elemento == 1 :\n",
    "            how_many_ones += 1\n",
    "            positions_1.append(i)\n",
    "\n",
    "\n",
    "        elif elemento == 0 :\n",
    "            how_many_zeroes += 1 \n",
    "            positions_0.append(i)\n",
    "    \n",
    "    # find the min = k \n",
    "    selected_value=min(how_many_ones, how_many_zeroes)\n",
    "\n",
    "    #  select only the first k elements from each vector\n",
    "    positions_1_sample = positions_1[:selected_value]\n",
    "    positions_0_sample = positions_0[:selected_value]\n",
    "\n",
    "    posizioni =   positions_1_sample + positions_0_sample\n",
    "    posizioni = sorted(posizioni)  \n",
    "    return posizioni\n",
    "\n",
    "def all_pos (vector):\n",
    "\n",
    "    \"\"\"  This function outputs a vector containing the positions of fragment pairs to extract in order to ensure generating the maximum possible number of balanced pairs.\n",
    "    \"\"\"\n",
    "\n",
    "   \n",
    "    positions = []\n",
    "\n",
    "    for i, elemento in enumerate(vector):\n",
    "        \n",
    "        positions.append(i)\n",
    "    posizioni = sorted(positions)  \n",
    "    return posizioni\n",
    "\n",
    "\n",
    "def max_the1_mod (vector):\n",
    "\n",
    "    \"\"\"  This function outputs a vector containing the positions of fragment pairs to extract in order to ensure generating the maximum possible number of balanced pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    how_many_ones = 0\n",
    "    how_many_zeroes = 0\n",
    "\n",
    "    positions_0 = []\n",
    "    positions_1 = []\n",
    " \n",
    "\n",
    "    for i, elemento in enumerate(vector):\n",
    "        if elemento == 1 :\n",
    "            how_many_ones += 1\n",
    "            positions_1.append(i)\n",
    "\n",
    "\n",
    "        elif elemento == 0 :\n",
    "            how_many_zeroes += 1 \n",
    "            positions_0.append(i)\n",
    "    \n",
    "    # find the min = k \n",
    "    selected_value=min(how_many_ones, how_many_zeroes)\n",
    "\n",
    "    if how_many_ones > how_many_zeroes:\n",
    "         extra_1= int((how_many_ones-how_many_zeroes)/3)\n",
    "         extra_0= 0\n",
    "    elif how_many_ones < how_many_zeroes:\n",
    "         extra_1= 0\n",
    "         extra_0= int((how_many_zeroes-how_many_ones)/3)\n",
    "    else:\n",
    "        extra_1= 0\n",
    "        extra_0= 0\n",
    "\n",
    "\n",
    "    #  select only the first k elements from each vector\n",
    "    positions_1_sample = positions_1[:selected_value + extra_1]\n",
    "    positions_0_sample = positions_0[:selected_value + extra_0]\n",
    "\n",
    "    posizioni =   positions_1_sample + positions_0_sample\n",
    "    posizioni = sorted(posizioni)  \n",
    "    return posizioni  \n",
    "\n",
    "\n",
    "\n",
    "def max_the_max (vector):\n",
    "\n",
    "    \"\"\"  This function outputs a vector containing the positions of fragment pairs to extract in order to ensure generating the maximum possible number of balanced pairs.\n",
    "    \"\"\"\n",
    "\n",
    "    how_many_ones = 0\n",
    "    how_many_zeroes = 0\n",
    "\n",
    "    positions_0 = []\n",
    "    positions_1 = []\n",
    " \n",
    "\n",
    "    for i, elemento in enumerate(vector):\n",
    "        if elemento == 1 :\n",
    "            how_many_ones += 1\n",
    "            positions_1.append(i)\n",
    "\n",
    "\n",
    "        elif elemento == 0 :\n",
    "            how_many_zeroes += 1 \n",
    "            positions_0.append(i)\n",
    "    \n",
    "    # find the min = k \n",
    "    selected_value=min(how_many_ones, how_many_zeroes)\n",
    "\n",
    "    if how_many_ones > how_many_zeroes:\n",
    "\n",
    "         positions_1_sample = random.sample(positions_1, selected_value)\n",
    "\n",
    "         positions_0_sample = positions_0[:selected_value]\n",
    "\n",
    "    elif how_many_ones < how_many_zeroes:\n",
    "\n",
    "         positions_1_sample = positions_1[:selected_value] \n",
    "         positions_0_sample = random.sample(positions_0, selected_value)\n",
    "\n",
    "    else:\n",
    "        positions_1_sample = positions_1[:selected_value]\n",
    "        positions_0_sample = positions_0[:selected_value]\n",
    "\n",
    "\n",
    "    posizioni =   positions_1_sample + positions_0_sample\n",
    "    posizioni = sorted(posizioni)  \n",
    "    return posizioni\n",
    "\n",
    "\n",
    "\n",
    "def max_the1_samples (vector):\n",
    "\n",
    "    how_many_ones = 0\n",
    "    how_many_zeroes = 0\n",
    "\n",
    "\n",
    "    positions_0 = []\n",
    "    positions_1 = []\n",
    " \n",
    "\n",
    "    for i, elemento in enumerate(vector):\n",
    "        if elemento == 1 :\n",
    "            how_many_ones += 1\n",
    "            positions_1.append(i)\n",
    "\n",
    "\n",
    "        elif elemento == 0 :\n",
    "            how_many_zeroes += 1 \n",
    "            positions_0.append(i)\n",
    "\n",
    "    selected_value=min(how_many_ones, how_many_zeroes)\n",
    "  \n",
    "    positions_1_sample = random.sample(positions_1, int((selected_value*3)/4))\n",
    "    positions_0_sample = random.sample(positions_0, int((selected_value*3)/4))\n",
    "\n",
    "    posizioni =   positions_1_sample + positions_0_sample\n",
    "    posizioni = sorted(posizioni)  \n",
    "    return posizioni\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def CreateCouples_intra_train_masked_pos(cluster_of_pt, adj_mat, posizioni):\n",
    "\n",
    "    \"\"\" This function is used to create the couples from the cluster in which each element is already preprocessed from the pct. \n",
    "        It doesn't create all possible pairs; in fact, by using the position vector, we know in which positions the pairs we need to extract are located\n",
    "        (those that allow us to have the maximum number of balanced pairs within the cluster).\n",
    "    \n",
    "    Input:\n",
    "        cluster_of_pt: the cluster of pointcloud (alredy processed from the PCT)\n",
    "        adj_mat: the adjacency matrix associated to the cluster\n",
    "        posizioni: the vector of positions obatined from max_the1_v() function\n",
    "    Return:\n",
    "        frag_a: the tensor of the first element of each couple\n",
    "        frag_b: the tensor of the second element of each couple\n",
    "        labels: a binary value that indicates if the couple is adjacent (1) or not (0)\n",
    "    \"\"\"\n",
    "    \n",
    "    frag_a = []\n",
    "    frag_b = []\n",
    "    labels = []\n",
    "    pos_realtime=0\n",
    "    # Discover the number of fragments\n",
    "    n_frags = len(adj_mat[0])\n",
    "    \n",
    "    for j in range(0, n_frags - 1):\n",
    "        init = j + 1\n",
    "        \n",
    "\n",
    "        for k in range(init, n_frags):\n",
    "            if pos_realtime in posizioni:  # Tests whether pos_realtime is contained in positions\n",
    "                frag_a_tensor = cluster_of_pt[j]\n",
    "                frag_b_tensor = cluster_of_pt[k]\n",
    "                label_value = adj_mat[j][k]\n",
    "\n",
    "                # Stack of tensors and labels at each step\n",
    "                if len(frag_a) == 0:\n",
    "                    frag_a = frag_a_tensor.unsqueeze(0)\n",
    "                    frag_b = frag_b_tensor.unsqueeze(0)\n",
    "                    labels = torch.tensor([label_value])\n",
    "                else:\n",
    "                    frag_a = torch.cat((frag_a, frag_a_tensor.unsqueeze(0)), dim=0)\n",
    "                    frag_b = torch.cat((frag_b, frag_b_tensor.unsqueeze(0)), dim=0)\n",
    "                    labels = torch.cat((labels, torch.tensor([label_value])), dim=0)\n",
    "\n",
    "            pos_realtime = pos_realtime + 1\n",
    "    \n",
    "    return frag_a, frag_b, labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptc_net = Branch()\n",
    "        self.pair_net = PairModel2()      \n",
    "\n",
    "    def forward(self, matrix, cluster, type_):\n",
    "        matrix = matrix.numpy()\n",
    "        # let's convert the matrix into a vector\n",
    "        y = adjmatrix_into_y(matrix[0])\n",
    "        # select the same number of 0 and 1 in the previous vector\n",
    "\n",
    "        if type_ == 0:\n",
    "            # all the position (unbalanced)\n",
    "            positions = all_pos(y)\n",
    "        elif type_ == 1:\n",
    "            # same 0 and 1 (balanced)\n",
    "            positions = max_the1_v(y)\n",
    "        elif type_ == 2:\n",
    "            # not the same 0 and 1 (little unbalanced)\n",
    "            positions = max_the1_mod(y)\n",
    "        elif type_ == 3: \n",
    "            # same 0 and 1 + sampling (balanced)    \n",
    "            positions = max_the_max(y)\n",
    "        else:\n",
    "            raise ValueError(\"Type can be only  0, 1, 2 or 3\")\n",
    "\n",
    "\n",
    "        #print(cluster[0])\n",
    "        # normalize each element of the cluster\n",
    "        cluster = apply_translation(cluster[0])\n",
    "        cluster = apply_randomrotations(cluster)\n",
    "        cluster = cluster.double().to(device)\n",
    "\n",
    "        # Salva l'ordine originale dei dati\n",
    "        original_order = np.arange(len(cluster))\n",
    "        #print(original_order)\n",
    "        # Esegui lo shuffle dei dati\n",
    "        np.random.shuffle(original_order)\n",
    "        #print(original_order)\n",
    "        cluster = cluster[original_order]\n",
    "\n",
    "        # create an empty tensor that will collect the trasformed fragments\n",
    "        cluster_transformed = torch.Tensor([]).to(device)\n",
    "\n",
    "        sub_cluster_start = 0\n",
    "        while sub_cluster_start < len(matrix[0][0]):\n",
    "            sub_cluster_end = min(sub_cluster_start + 16, len(matrix[0][0]))\n",
    "            cluster_subset = cluster[sub_cluster_start:sub_cluster_end]\n",
    "            cluster_subset = cluster_subset.to(device)\n",
    "            # apply the PCT\n",
    "            point_clouds_transformed = self.ptc_net(cluster_subset)\n",
    "            # append the results\n",
    "            cluster_transformed = torch.cat((cluster_transformed, point_clouds_transformed), dim=0)\n",
    "            sub_cluster_start += 16\n",
    "\n",
    "\n",
    "        #print(cluster_transformed)\n",
    "        sorted_indices = np.argsort(original_order)\n",
    "\n",
    "        # Applica il riordino a cluster_transformed\n",
    "        cluster_transformed = cluster_transformed[sorted_indices]\n",
    "        # Ripristina l'ordine originale dei dati trasformati\n",
    "        #cluster_transformed = cluster_transformed[torch.tensor(original_order)]\n",
    "        #print(cluster_transformed)\n",
    "        # given the positions, the matrix and the transformed cluster create the couples\n",
    "        frags_a, frags_b, labels = CreateCouples_intra_train_masked_pos(cluster_transformed, matrix[0], positions)\n",
    "        \n",
    "        \n",
    "\n",
    "        #######\n",
    "        # Shuffle the pairs and labels randomly\n",
    "        #perm = torch.randperm(frags_a.size(0))\n",
    "        #frags_a = frags_a[perm]\n",
    "        #frags_b = frags_b[perm]\n",
    "        #labels = labels[perm]\n",
    "        #######\n",
    "\n",
    "        frags_a = frags_a.double().to(device)\n",
    "        frags_b = frags_b.double().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Calculate positive and negative couples\n",
    "        x_mult = frags_a * frags_b  # Sum the two elements of the couples\n",
    "        x_sum = frags_a * frags_b   # Multiply the two elements of the couples\n",
    "\n",
    "        # Combine positive and negative couples into a single tensor\n",
    "        #positive_couples = torch.cat((x_mult[labels == 1], x_sum[labels == 1]), dim=1)\n",
    "        #negative_couples = torch.cat((x_mult[labels == 0], x_sum[labels == 0]), dim=1)\n",
    "        \n",
    "        embeddings = torch.cat((x_mult, x_sum), dim = 1)\n",
    "\n",
    "        cosine_similarities = F.cosine_similarity(frags_a, frags_b)\n",
    "\n",
    "        min_value = torch.min(cosine_similarities)\n",
    "        max_value = torch.max(cosine_similarities)\n",
    "        scaled_similarities = (cosine_similarities - min_value) / (max_value - min_value)\n",
    "        one_minus_scaled = 1 - scaled_similarities\n",
    "\n",
    "        result_tensor = torch.cat((one_minus_scaled.view(-1, 1), scaled_similarities.view(-1, 1)), dim=1) \n",
    "        return result_tensor, labels, frags_a, frags_b, embeddings\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class PairModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        output_channels = 2 # it's a binary classification\n",
    "\n",
    "      \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "        # classificator\n",
    "        self.linear0 = nn.Linear(2048, 1024, bias=False)\n",
    "        self.bn0 = nn.BatchNorm1d(1024)\n",
    "        self.dp0 = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dp2 = nn.Dropout(p=0.3)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dp3 = nn.Dropout(p=0.3)\n",
    "        self.linear4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dp4 = nn.Dropout(p=0.3)\n",
    "        self.linear5 = nn.Linear(64, output_channels)\n",
    "        \n",
    "    def forward(self, x_1, x_2):\n",
    "       \n",
    "        x_mult = x_1 * x_2 # sum the two elements of the couples\n",
    "        x_sum = x_1 * x_2 # multiply the two elements of the couples\n",
    "        x = torch.cat((x_mult, x_sum), dim = 1) \n",
    "\n",
    "        # classificator\n",
    "        if x_1.shape[0] > 1:\n",
    "            x = self.relu(self.bn0(self.linear0(x)))\n",
    "            #x = self.dp0(x)\n",
    "            x = self.relu(self.bn1(self.linear1(x)))\n",
    "            x = self.dp1(x)\n",
    "            x = self.relu(self.bn2(self.linear2(x)))\n",
    "            x = self.dp2(x)\n",
    "            x = self.relu(self.bn3(self.linear3(x)))\n",
    "            x = self.dp3(x)\n",
    "            x = self.relu(self.bn4(self.linear4(x)))\n",
    "            x = self.dp4(x)\n",
    "            x = self.linear5(x)\n",
    "\n",
    "        # If we have only one pair, applying batch normalization doesn't make sense.\n",
    "        else: \n",
    "            x = self.relu(self.linear0(x))\n",
    "            #x = self.dp0(x)\n",
    "            x = self.relu(self.linear1(x))\n",
    "            x = self.dp1(x)\n",
    "            x = self.relu(self.linear2(x))\n",
    "            x = self.dp2(x)\n",
    "            x = self.relu(self.linear3(x))\n",
    "            x = self.dp3(x)\n",
    "            x = self.relu(self.linear4(x))\n",
    "            x = self.dp4(x)\n",
    "            x = self.linear5(x)\n",
    "                    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 is available and being used\n"
     ]
    }
   ],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.tolist()\n",
    "val = val.tolist()\n",
    "# We process one cluster at a time.\n",
    "train_loader = DataLoader(train, batch_size=1)\n",
    "val_loader = DataLoader(val, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model2_mod(\n",
       "  (ptc_net): Branch(\n",
       "    (conv1): Conv1d(7, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (gather_local_0): Local_op(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (gather_local_1): Local_op(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pt_last): StackedAttention(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sa1): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa2): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa3): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa4): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (conv_fuse): Sequential(\n",
       "      (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (pair_net): PairModel2(\n",
       "    (relu): ReLU()\n",
       "    (linear0): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "    (bn0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp0): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp1): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp2): Dropout(p=0.3, inplace=False)\n",
       "    (linear3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp3): Dropout(p=0.3, inplace=False)\n",
       "    (linear4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp4): Dropout(p=0.3, inplace=False)\n",
       "    (linear5): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Model2_mod().to(device)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\1010_180133_13+lr=0.0001+leggermenteunbalanced.pt')\n",
    "model.load_state_dict(W_stored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, m=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, y1, y2, d):\n",
    "        euc_dist = torch.nn.functional.pairwise_distance(y1, y2)\n",
    "\n",
    "        if d.dim() == 0:  # Se d è uno scalare\n",
    "            if d == 0:\n",
    "                return torch.mean(torch.pow(euc_dist, 2))  # Distanza quadratica\n",
    "            else:  # d == 1\n",
    "                delta = self.m - euc_dist\n",
    "                delta = torch.clamp(delta, min=0.0, max=None)\n",
    "                return torch.mean(torch.pow(delta, 2))\n",
    "        else:  # Se d è un tensore di valori 0 e 1\n",
    "            is_same = d == 0\n",
    "            is_diff = d == 1\n",
    "\n",
    "            loss_same = torch.pow(euc_dist[is_same], 2).mean() if torch.any(is_same) else torch.tensor(0.0).to(euc_dist.device)\n",
    "            loss_diff = torch.pow(torch.clamp(self.m - euc_dist[is_diff], min=0.0), 2).mean() if torch.any(is_diff) else torch.tensor(0.0).to(euc_dist.device)\n",
    "\n",
    "            return (loss_same + loss_diff) / (1.0 + torch.any(is_same).float() + torch.any(is_diff).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:s7u9sf8v) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43828978e87a494baec68c4bed52056a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">flowing-sunset-9</strong> at: <a href='https://wandb.ai/pair_fragments/first_trial/runs/s7u9sf8v' target=\"_blank\">https://wandb.ai/pair_fragments/first_trial/runs/s7u9sf8v</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231012_091935-s7u9sf8v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:s7u9sf8v). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c951a4742945b9a30ef915b57898e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\wandb\\run-20231012_092220-787j20ri</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pair_fragments/first_trial/runs/787j20ri' target=\"_blank\">grateful-totem-10</a></strong> to <a href='https://wandb.ai/pair_fragments/first_trial' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pair_fragments/first_trial' target=\"_blank\">https://wandb.ai/pair_fragments/first_trial</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pair_fragments/first_trial/runs/787j20ri' target=\"_blank\">https://wandb.ai/pair_fragments/first_trial/runs/787j20ri</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\model_pairV2.ipynb Cell 22\u001b[0m line \u001b[0;36m8\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/model_pairV2.ipynb#X30sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/model_pairV2.ipynb#X30sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/model_pairV2.ipynb#X30sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(cluster_outputs_\u001b[39m.\u001b[39;49mdata, \u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/model_pairV2.ipynb#X30sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m train_of_results\u001b[39m.\u001b[39mappend(predicted\u001b[39m.\u001b[39mtolist())\n",
      "\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/model_pairV2.ipynb#X30sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m total_samples \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m one_hot_labels_\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"first_trial\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "  \n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.0004,\n",
    "      \"architecture\": \"Model2_mod\",\n",
    "      \"dataset\": \"max_the_max sampled\",\n",
    "      \"epochs\": 5,\n",
    "      \"weight_decay\": 0.00001,\n",
    "      \"W_crossentropy\":1,\n",
    "      \"W_contrastive\":0.05,\n",
    "      \"type_of_couples\": 1,\n",
    "      \"seed\": seed\n",
    "      })\n",
    "      \n",
    "config = wandb.config\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "contrast_criterion = ContrastiveLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "num_epochs = config.epochs\n",
    "best_val_accuracy = 0.0 \n",
    "\n",
    "\n",
    "\n",
    "#miner = miners.MultiSimilarityMiner()\n",
    "#loss_func = losses.TripletMarginLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "results_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\results'\n",
    "\n",
    "checkpoint_interval = 1  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    list_of_results=[]\n",
    "    list_of_true=[]\n",
    "\n",
    "    train_of_results=[]\n",
    "    train_of_true=[]\n",
    "    model.train() \n",
    "\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "\n",
    "    ###########\n",
    "    ## Train ##\n",
    "    ###########\n",
    "    \n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "    for batch_data in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        matrix, cluster = batch_data\n",
    "\n",
    "        cluster_outputs_, labels_, frags_a, frags_b, embeddings = model(matrix, cluster,config.type_of_couples)\n",
    "        one_hot_labels_ = F.one_hot(labels_,2)\n",
    "        #hard_pairs = miner(cluster_outputs_, labels_)\n",
    "\n",
    "        train_of_true.append(labels_.tolist())\n",
    "\n",
    "        #print(len(hard_pairs))\n",
    "        #print(hard_pairs[0])\n",
    "        #loss__ = loss_func(torch.cat((frags_a, frags_b), dim = 1), labels_)\n",
    "        loss_ = criterion(cluster_outputs_, one_hot_labels_.float())\n",
    "        contrast_loss = contrast_criterion(frags_a, frags_b, labels_)\n",
    "       \n",
    "        loss = loss_ + config.W_contrastive*contrast_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "       \n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(cluster_outputs_.data, 1)\n",
    "\n",
    "        train_of_results.append(predicted.tolist())\n",
    "\n",
    "        total_samples += one_hot_labels_.size(0)\n",
    "        correct_predictions += (predicted == labels_).sum().item()\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': correct_predictions / total_samples})\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    train_loss = total_loss/len(train_loader)\n",
    "\n",
    "    metrics_train = {\"train_loss\": train_loss, \n",
    "                       \"accuracy\": accuracy}\n",
    "    wandb.log(metrics_train)\n",
    "\n",
    "    ###############\n",
    "    ## Inference ##\n",
    "    ###############\n",
    "\n",
    "    model.eval()  \n",
    "    \n",
    "    val_loss_ = 0.0\n",
    "    v_contrast_loss= 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "            \n",
    "            val_outputs_, val_labels_, v_frags_a, v_frags_b, embeddings = model(val_matrix, val_cluster, config.type_of_couples)\n",
    "            \n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "             \n",
    "   \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "    val_metrics = {\"val_loss\": val_loss, \n",
    "                       \"val_accuracy\": val_accuracy}\n",
    "    wandb.log(val_metrics)                   \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {accuracy:.4f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "    result_path = os.path.join(results_dir, f\"+lr=0.0004results_epoch_{epoch+1}\")              #############################\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(result_path, \"list_of_true.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_true, f)\n",
    "\n",
    "    with open(os.path.join(result_path, \"list_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_results, f)\n",
    "\n",
    "    train_result_path = os.path.join(results_dir, f\"TRAIN+lr=0.0004_results_epoch_{epoch+1}\")             ##################  \n",
    "    os.makedirs(train_result_path, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(train_result_path, \"train_of_true.pkl\" ), 'wb') as f:\n",
    "        pickle.dump(train_of_true, f)\n",
    "\n",
    "    with open(os.path.join(train_result_path, \"train_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(train_of_results, f)    \n",
    "\n",
    "    current_time = datetime.datetime.now()\n",
    "    checkpoint_name = f\"{current_time.strftime('%m%d_%H%M%S')}_{epoch+1}+lr=0.0004+sampled_coupels.pt\"    #################\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.tolist()\n",
    "\n",
    "# We process one cluster at a time.\n",
    "test_loader = DataLoader(test, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\1006_171026_3+2contrastivelosses.pt')\n",
    "\n",
    "model.load_state_dict(W_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6339391045446885\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▇▇█▇</td></tr><tr><td>train_loss</td><td>█▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃█▁</td></tr><tr><td>val_loss</td><td>▅█▁▄▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.62644</td></tr><tr><td>test_accuracy</td><td>0.63394</td></tr><tr><td>train_loss</td><td>0.69466</td></tr><tr><td>val_accuracy</td><td>0.63237</td></tr><tr><td>val_loss</td><td>0.69288</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-leaf-8</strong> at: <a href='https://wandb.ai/pair_fragments/first_trial/runs/xandtam4' target=\"_blank\">https://wandb.ai/pair_fragments/first_trial/runs/xandtam4</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231011_171715-xandtam4\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval() \n",
    "epoch=0 \n",
    "list_of_results=[]\n",
    "list_of_true=[]    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "contrast_criterion = ContrastiveLoss()\n",
    "results_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\results'\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in test_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "            \n",
    "            val_outputs_, val_labels_, v_frags_a, v_frags_b, embeddings = model(val_matrix, val_cluster)\n",
    "           \n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "             \n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss = val_loss_ + 0.05*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "val_accuracy = val_correct_predictions / val_total_samples\n",
    "val_loss /= len(val_loader)\n",
    "print(val_accuracy)\n",
    "wandb.summary['test_accuracy'] = val_accuracy\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
