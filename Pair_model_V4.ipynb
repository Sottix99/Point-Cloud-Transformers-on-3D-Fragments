{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import special_ortho_group\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import torch.nn.functional as F\n",
    "from pytorch_metric_learning import miners, losses\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=999\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msottile124\u001b[0m (\u001b[33mpair_fragments\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_GPU():\n",
    "    \"\"\" This function activates the gpu \n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(torch.cuda.get_device_name(0), \"is available and being used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU is not available, using CPU instead\") \n",
    "    return device  \n",
    "\n",
    "\n",
    "def center_in_origin(frag):\n",
    "    \"\"\" This function normalize each fragment in (0,1)\n",
    "    \"\"\"\n",
    "    min_vals, _ = torch.min(frag[:, 0:3], axis=0)\n",
    "    max_vals, _ = torch.max(frag[:, 0:3], axis=0)\n",
    "    frag[:, 0:3] = (frag[:, 0:3] - min_vals) / (max_vals - min_vals)\n",
    "    \n",
    "    return frag\n",
    "    \n",
    "def normalize(batch):\n",
    "    \"\"\" This function apply center_in_origin() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(center_in_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor  \n",
    "\n",
    "\n",
    "\n",
    "def translate_to_origin(frag):\n",
    "    \"\"\" This function translate each fragment in the origin\n",
    "    \"\"\"\n",
    "    frag[:,:3] -= torch.mean(frag[:,:3]) \n",
    "    return frag\n",
    "\n",
    "def apply_translation(batch):\n",
    "    \"\"\" This function apply translate_to_origin() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(translate_to_origin(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor\n",
    "\n",
    "\n",
    "def random_rotation(frag):\n",
    "\n",
    "    randrot = (torch.rand(3)*360).tolist()\n",
    "    r = R.from_euler('zyx', randrot, degrees=True)\n",
    "    frag[:,:3] = torch.from_numpy(r.apply(frag[:,:3]))\n",
    "    frag[:,3:6] = torch.from_numpy(r.apply(frag[:,3:6]))\n",
    "    return frag\n",
    "\n",
    "def apply_randomrotations(batch):\n",
    "    \"\"\" This function apply random_rotation() to each fragment in the batch\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    for element in batch:\n",
    "        out.append(random_rotation(element))\n",
    "    out_tensor = torch.stack(out)    \n",
    "    return out_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code form the repository of PCT https://github.com/qq456cvb/Point-Transformers\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zm；\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    return torch.sum((src[:, :, None] - dst[:, None]) ** 2, dim=-1)\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)\n",
    "\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        distance = torch.min(distance, dist)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def sample_and_group(npoint, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint \n",
    "    \n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint]\n",
    "\n",
    "    new_xyz = index_points(xyz, fps_idx) \n",
    "    new_points = index_points(points, fps_idx)\n",
    "\n",
    "    dists = square_distance(new_xyz, xyz)  # B x npoint x N\n",
    "    idx = dists.argsort()[:, :, :nsample]  # B x npoint x K\n",
    "\n",
    "    grouped_points = index_points(points, idx)\n",
    "    grouped_points_norm = grouped_points - new_points.view(B, S, 1, -1)\n",
    "    new_points = torch.cat([grouped_points_norm, new_points.view(B, S, 1, -1).repeat(1, 1, nsample, 1)], dim=-1)\n",
    "    return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Local_op(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, s, d = x.size()  # torch.Size([32, 512, 32, 6]) \n",
    "        x = x.permute(0, 1, 3, 2)\n",
    "        x = x.reshape(-1, d, s)\n",
    "        batch_size, _, N = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = x.reshape(b, n, -1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SA_Layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n",
    "        x = x + x_r\n",
    "        return x\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class StackedAttention(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer(channels)\n",
    "        self.sa2 = SA_Layer(channels)\n",
    "        self.sa3 = SA_Layer(channels)\n",
    "        self.sa4 = SA_Layer(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same as before but witch classical attention \n",
    "class SA_Layer_classic(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x_r)))\n",
    "        \n",
    "        return x_r\n",
    "\n",
    "\n",
    "class StackedAttention_classic(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer_classic(channels)\n",
    "        self.sa2 = SA_Layer_classic(channels)\n",
    "        self.sa3 = SA_Layer_classic(channels)\n",
    "        self.sa4 = SA_Layer_classic(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        d_points = 7 # we have 7 features for each point\n",
    "        self.conv1 = nn.Conv1d(d_points, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.gather_local_0 = Local_op(in_channels=128, out_channels=128)\n",
    "        self.gather_local_1 = Local_op(in_channels=256, out_channels=256)\n",
    "        self.pt_last = StackedAttention()###############################################################\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm1d(1024),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xyz = x[..., :3]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        batch_size, _, _ = x.size()\n",
    "        x= x.double()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = x.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=512, nsample=32, xyz=xyz, points=x)         \n",
    "        feature_0 = self.gather_local_0(new_feature)\n",
    "        feature = feature_0.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=256, nsample=32, xyz=new_xyz, points=feature) \n",
    "        feature_1 = self.gather_local_1(new_feature)\n",
    "        \n",
    "        x = self.pt_last(feature_1)\n",
    "        x = torch.cat([x, feature_1], dim=1)\n",
    "        x = self.conv_fuse(x)\n",
    "        x = torch.max(x, 2)[0] # Returns the maximum value of all elements in the input tensor. (2 elementes for each vector)\n",
    "        x = x.view(batch_size, -1) # Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "def apply_cosine_sim(A,B):\n",
    "    cosine_similarities = F.cosine_similarity(A, B)\n",
    "\n",
    "    min_value = torch.min(cosine_similarities)\n",
    "    max_value = torch.max(cosine_similarities)\n",
    "    scaled_similarities = (cosine_similarities - min_value) / (max_value - min_value)\n",
    "    one_minus_scaled = 1 - scaled_similarities\n",
    "    result_tensor = torch.cat((one_minus_scaled.view(-1, 1), scaled_similarities.view(-1, 1)), dim=1) \n",
    "    return result_tensor    \n",
    "\n",
    "\n",
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, m=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, y1, y2, d):\n",
    "        euc_dist = torch.nn.functional.pairwise_distance(y1, y2)\n",
    "\n",
    "        if d.dim() == 0:  # Se d è uno scalare\n",
    "            if d == 0:\n",
    "                return torch.mean(torch.pow(euc_dist, 2))  # Distanza quadratica\n",
    "            else:  # d == 1\n",
    "                delta = self.m - euc_dist\n",
    "                delta = torch.clamp(delta, min=0.0, max=None)\n",
    "                return torch.mean(torch.pow(delta, 2))\n",
    "        else:  # Se d è un tensore di valori 0 e 1\n",
    "            is_same = d == 0\n",
    "            is_diff = d == 1\n",
    "\n",
    "            loss_same = torch.pow(euc_dist[is_same], 2).mean() if torch.any(is_same) else torch.tensor(0.0).to(euc_dist.device)\n",
    "            loss_diff = torch.pow(torch.clamp(self.m - euc_dist[is_diff], min=0.0), 2).mean() if torch.any(is_diff) else torch.tensor(0.0).to(euc_dist.device)\n",
    "\n",
    "            return (loss_same + loss_diff) / (1.0 + torch.any(is_same).float() + torch.any(is_diff).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "train = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\train_pair_dataset_REG.pt\")\n",
    "val = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\val_pair_dataset_REG.pt\")\n",
    "test = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\test_pair_dataset_REG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions to remove (Train): [2, 14, 20, 22, 28, 30, 31, 35, 36, 39, 71, 78, 87, 91, 95, 109, 136, 148, 163, 167, 192, 197, 205, 209, 215, 217, 218, 222, 228, 241, 255, 261, 263, 265, 273, 284, 300, 308, 318, 337, 344, 346, 353, 361, 364, 369, 398, 420, 423, 427, 431, 433, 468, 469, 471, 474, 489, 494, 496, 507, 513, 516, 517, 538, 547, 551, 564, 577, 591, 595, 597, 600, 607, 613, 617, 633, 635, 644, 651, 652, 660, 664, 675, 689, 694, 699, 700, 707, 711, 721, 731, 735, 754, 757, 758, 763, 768, 771, 776, 783, 789, 813, 818, 831, 834, 837, 841, 844, 846, 874, 879, 896, 909, 917, 931, 943, 971, 977, 979, 988, 991, 994, 996, 999, 1042, 1045, 1050, 1057, 1077, 1078, 1079, 1084, 1100, 1109, 1118, 1126, 1127, 1129, 1130, 1131, 1143, 1150, 1156, 1188, 1217, 1219, 1227, 1254, 1274, 1284, 1290, 1295, 1299, 1316, 1324, 1334, 1336, 1337, 1347, 1353, 1356, 1390, 1392, 1412, 1418, 1460, 1463, 1466, 1469, 1474, 1483, 1489, 1498, 1499, 1504, 1505, 1507, 1514]\n",
      "Positions to remove (Val): [6, 12, 13, 22, 24, 31, 65, 70, 77, 94, 105, 118, 125, 137, 145, 147, 157, 162, 169, 173, 177, 180, 187, 192, 196, 216, 219, 241, 255, 281, 293, 294, 300, 301, 308]\n",
      "Positions to remove (Test): [3, 34, 36, 41, 48, 50, 60, 69, 91, 92, 93, 96, 99, 112, 123, 135, 140, 141, 151, 166, 177, 186, 189, 232, 238, 244, 246, 251, 255, 262, 266, 267, 271, 304, 312, 316, 322, 326]\n",
      "(1348, 2)\n",
      "(292, 2)\n",
      "(289, 2)\n"
     ]
    }
   ],
   "source": [
    "#let's find the largest clusters\n",
    "\n",
    "threshold = 70\n",
    "\n",
    "# Train\n",
    "indices = [i for i, data in enumerate(train) if data[0].shape[0] > threshold]\n",
    "count = len(indices)\n",
    "\n",
    "# Val\n",
    "indices_val = [i for i, data in enumerate(val) if data[0].shape[0] > threshold]\n",
    "count_val = len(indices_val)\n",
    "\n",
    "# Test\n",
    "indices_test = [i for i, data in enumerate(test) if data[0].shape[0] > threshold]\n",
    "count_test = len(indices_test)\n",
    "\n",
    "print(\"Positions to remove (Train):\", indices)\n",
    "print(\"Positions to remove (Val):\", indices_val)\n",
    "print(\"Positions to remove (Test):\", indices_test)\n",
    "\n",
    "\n",
    "# We are removing the largest clusters for computational reasons\n",
    "mask = torch.ones(train.shape[0], dtype=torch.bool)\n",
    "mask[indices] = False\n",
    "filtered_tensor = train[mask]\n",
    "train = filtered_tensor\n",
    "\n",
    "mask_val = torch.ones(val.shape[0], dtype=torch.bool)\n",
    "mask_val[indices_val] = False\n",
    "filtered_tensor_val = val[mask_val]\n",
    "val = filtered_tensor_val\n",
    "\n",
    "mask_test = torch.ones(test.shape[0], dtype=torch.bool)\n",
    "mask_test[indices_test] = False\n",
    "filtered_tensor_test = test[mask_test]\n",
    "test= filtered_tensor_test   \n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_pos (vector):\n",
    "\n",
    "    positions = np.arange(len(vector))  \n",
    "    labels = torch.Tensor(vector)\n",
    "    return positions, labels\n",
    "\n",
    "\n",
    "def fixed_and_balanced (vector):\n",
    "\n",
    "    labels = torch.Tensor(vector)\n",
    "    num = min((labels==0).int().sum(), (labels==1).int().sum())\n",
    "    \n",
    "    zero_indices = (labels == 0).nonzero()[:num, 0]\n",
    "    one_indices = (labels == 1).nonzero()[:num, 0]\n",
    "    combined_indices = torch.sort(torch.cat((zero_indices, one_indices)))\n",
    "    \n",
    "    selected_labels = labels[combined_indices.values]\n",
    "    return combined_indices.values.tolist(), selected_labels \n",
    "\n",
    "def fixed_and_unbalanced (vector):\n",
    "     \n",
    "    labels = torch.Tensor(vector)\n",
    "    num_zeroes = (labels==0).int().sum() \n",
    "    num_ones = (labels==1).int().sum()\n",
    "    num = min(num_zeroes, num_ones)\n",
    "    \n",
    "    extra_1= int((num_ones-num_zeroes)/3)\n",
    "    extra_0= int((num_zeroes-num_ones)/3)\n",
    "    \n",
    "    zero_indices = (labels == 0).nonzero()[:num + extra_0, 0]\n",
    "    one_indices = (labels == 1).nonzero()[:num + extra_1, 0]\n",
    "    combined_indices = torch.sort(torch.cat((zero_indices, one_indices)))\n",
    "    \n",
    "    selected_labels = labels[combined_indices.values]\n",
    "    return combined_indices.values.tolist(), selected_labels  \n",
    "\n",
    "def sampled_balanced (vector):\n",
    "\n",
    "    labels = torch.Tensor(vector)\n",
    "    num_zeroes = (labels==0).int().sum() \n",
    "    num_ones = (labels==1).int().sum()\n",
    "    num = min(num_zeroes, num_ones)\n",
    "\n",
    "    zero_indices = (labels == 0).nonzero()[:num, 0]\n",
    "    one_indices = (labels == 1).nonzero()[:num, 0]\n",
    "\n",
    "    one_indices = one_indices[torch.randperm(one_indices.size(0))][:num]\n",
    "    zero_indices = zero_indices[torch.randperm(zero_indices.size(0))][:num]\n",
    "     \n",
    "    combined_indices = torch.sort(torch.cat((zero_indices, one_indices)))\n",
    "    \n",
    "    selected_labels = labels[combined_indices.values]\n",
    "    \n",
    "    return combined_indices.values.tolist(), selected_labels \n",
    "\n",
    "\n",
    "    \n",
    "def select_couples(y,type_):\n",
    "    \"\"\" \n",
    "    ## type == 0 : select all the positions\n",
    "\n",
    "    ## type == 1: let k = min(numbers of zeros, numbers of ones), select the first k zeros and the first k ones every time (always the same couples in each cluster)\n",
    "           \n",
    "    ## type == 2: let k = min(numbers of zeros, numbers of ones), select all the k elements of the minority class and  k + (#majority - #minority)/3 (always the same couples in each cluster)\n",
    "        \n",
    "    ## type == 3 : let k = min(numbers of zeros, numbers of ones), select all the k elements of the minority class and sample k elements from the majority one\"\"\"\n",
    "\n",
    "\n",
    "    if type_ == 0:\n",
    "                # all the position (unbalanced)\n",
    "            positions, lab = all_pos(y)\n",
    "    elif type_ == 1:\n",
    "            # same 0 and 1 (balanced)\n",
    "            positions, lab = fixed_and_balanced(y)\n",
    "            \n",
    "    elif type_ == 2:\n",
    "            # not the same 0 and 1 (unbalanced)\n",
    "            positions, lab = fixed_and_unbalanced(y)\n",
    "    elif type_ == 3: \n",
    "            # same 0 and 1 + sampling (balanced)    \n",
    "            positions, lab = sampled_balanced(y)\n",
    "    else:\n",
    "            raise ValueError(\"Type can be only  0, 1, 2 or 3\")\n",
    "    return positions, lab    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairModel2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        output_channels = 2 # it's a binary classification\n",
    "\n",
    "      \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "            \n",
    "        # classificator\n",
    "        self.linear0 = nn.Linear(2048, 1024, bias=False)\n",
    "        self.bn0 = nn.BatchNorm1d(1024)\n",
    "        self.dp0 = nn.Dropout(p=0.5)\n",
    "        self.linear1 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dp1 = nn.Dropout(p=0.2)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dp2 = nn.Dropout(p=0.3)\n",
    "        self.linear3 = nn.Linear(256, 128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.dp3 = nn.Dropout(p=0.3)\n",
    "        self.linear4 = nn.Linear(128, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.dp4 = nn.Dropout(p=0.3)\n",
    "        self.linear5 = nn.Linear(64, output_channels)\n",
    "        \n",
    "    def forward(self, x_1, x_2):\n",
    "       \n",
    "        x_mult = x_1 * x_2 # sum the two elements of the couples\n",
    "        x_sum = x_1 * x_2 # multiply the two elements of the couples\n",
    "        x = torch.cat((x_mult, x_sum), dim = 1) \n",
    "\n",
    "        # classificator\n",
    "        if x_1.shape[0] > 1:\n",
    "            x = self.relu(self.bn0(self.linear0(x)))\n",
    "            #x = self.dp0(x)\n",
    "            x = self.relu(self.bn1(self.linear1(x)))\n",
    "            x = self.dp1(x)\n",
    "            x = self.relu(self.bn2(self.linear2(x)))\n",
    "            x = self.dp2(x)\n",
    "            x = self.relu(self.bn3(self.linear3(x)))\n",
    "            x = self.dp3(x)\n",
    "            x = self.relu(self.bn4(self.linear4(x)))\n",
    "            x = self.dp4(x)\n",
    "            x = self.linear5(x)\n",
    "\n",
    "        # If we have only one pair, applying batch normalization doesn't make sense.\n",
    "        else: \n",
    "            x = self.relu(self.linear0(x))\n",
    "            #x = self.dp0(x)\n",
    "            x = self.relu(self.linear1(x))\n",
    "            x = self.dp1(x)\n",
    "            x = self.relu(self.linear2(x))\n",
    "            x = self.dp2(x)\n",
    "            x = self.relu(self.linear3(x))\n",
    "            x = self.dp3(x)\n",
    "            x = self.relu(self.linear4(x))\n",
    "            x = self.dp4(x)\n",
    "            x = self.linear5(x)\n",
    "\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Model2_mod(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.ptc_net = Branch()\n",
    "        self.pair_net = PairModel2()      \n",
    "\n",
    "    def forward(self,cluster, positions, n_frags):\n",
    "        for param in self.ptc_net.parameters():\n",
    "           param.requires_grad = False\n",
    "        cluster = cluster.double().to(device)\n",
    "\n",
    "        # Salva l'ordine originale dei dati\n",
    "        original_order = np.arange(len(cluster))\n",
    "        # Esegui lo shuffle dei dati\n",
    "        np.random.shuffle(original_order)\n",
    "        cluster = cluster[original_order]\n",
    "\n",
    "        # create an empty tensor that will collect the trasformed fragments\n",
    "        cluster_transformed = torch.Tensor([]).to(device)\n",
    "\n",
    "        sub_cluster_start = 0\n",
    "        while sub_cluster_start < n_frags:\n",
    "            sub_cluster_end = min(sub_cluster_start + 16, n_frags)\n",
    "            cluster_subset = cluster[sub_cluster_start:sub_cluster_end]\n",
    "            cluster_subset = cluster_subset.to(device)\n",
    "            # apply the PCT\n",
    "            point_clouds_transformed = self.ptc_net(cluster_subset)\n",
    "            # append the results\n",
    "            cluster_transformed = torch.cat((cluster_transformed, point_clouds_transformed), dim=0)\n",
    "            sub_cluster_start += 16\n",
    "\n",
    "        sorted_indices = np.argsort(original_order)\n",
    "        cluster_transformed = cluster_transformed[sorted_indices]\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        # given the positions and the transformed cluster create the couples\n",
    "        indices = torch.triu_indices(n_frags, n_frags, offset=1)\n",
    "    \n",
    "        # Seleziona solo gli indici che corrispondono a posizioni desiderate\n",
    "        selected_indices = indices[:, positions]\n",
    "        \n",
    "        # Estrai i tensori dai frammenti selezionati\n",
    "        frags_a = cluster_transformed[selected_indices[0]]\n",
    "        frags_b = cluster_transformed[selected_indices[1]] \n",
    "\n",
    "        frags_a = frags_a.double().to(device)\n",
    "        frags_b = frags_b.double().to(device)\n",
    "    \n",
    "        outputs = self.pair_net(frags_a, frags_b)  \n",
    "        return outputs, frags_a, frags_b\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 is available and being used\n"
     ]
    }
   ],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.tolist()\n",
    "val = val.tolist()\n",
    "\n",
    "# We process one cluster at a time.\n",
    "train_loader = DataLoader(train, batch_size=1,shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size=1,shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model2_mod(\n",
       "  (ptc_net): Branch(\n",
       "    (conv1): Conv1d(7, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (conv2): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "    (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (gather_local_0): Local_op(\n",
       "      (conv1): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(128, 128, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (gather_local_1): Local_op(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (pt_last): StackedAttention(\n",
       "      (conv1): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (sa1): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa2): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa3): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (sa4): SA_Layer(\n",
       "        (q_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (k_conv): Conv1d(256, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        (v_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (trans_conv): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "        (after_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "        (softmax): Softmax(dim=-1)\n",
       "      )\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (relu): ReLU()\n",
       "    (conv_fuse): Sequential(\n",
       "      (0): Conv1d(1280, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): LeakyReLU(negative_slope=0.2)\n",
       "    )\n",
       "  )\n",
       "  (pair_net): PairModel2(\n",
       "    (relu): ReLU()\n",
       "    (linear0): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "    (bn0): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp0): Dropout(p=0.5, inplace=False)\n",
       "    (linear1): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp1): Dropout(p=0.2, inplace=False)\n",
       "    (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp2): Dropout(p=0.3, inplace=False)\n",
       "    (linear3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp3): Dropout(p=0.3, inplace=False)\n",
       "    (linear4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (bn4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dp4): Dropout(p=0.3, inplace=False)\n",
       "    (linear5): Linear(in_features=64, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model2_mod().to(device)\n",
    "model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\19_10_1209_2_random_choice_and_frozen_layers.pt')  \n",
    "\n",
    "model.load_state_dict(W_stored)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msottile124\u001b[0m (\u001b[33mpair_fragments\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\wandb\\run-20231019_113344-jefrec82</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pair_fragments/Modello_ottimizzato/runs/jefrec82' target=\"_blank\">balmy-flower-9</a></strong> to <a href='https://wandb.ai/pair_fragments/Modello_ottimizzato' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pair_fragments/Modello_ottimizzato' target=\"_blank\">https://wandb.ai/pair_fragments/Modello_ottimizzato</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pair_fragments/Modello_ottimizzato/runs/jefrec82' target=\"_blank\">https://wandb.ai/pair_fragments/Modello_ottimizzato/runs/jefrec82</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(\n",
    "      # Set the project where this run will be logged\n",
    "      project=\"Modello_ottimizzato\", \n",
    "      # We pass a run name (otherwise it’ll be randomly assigned, like sunshine-lollypop-10)\n",
    "      notes = \"random coppie + finetuning con layer congelati\",\n",
    "      # Track hyperparameters and run metadata\n",
    "      config={\n",
    "      \"learning_rate\": 0.0002,\n",
    "      \"architecture\": \"Model2_mod\",\n",
    "      \"epochs\": 10,\n",
    "      \"weight_decay\": 0.00005,\n",
    "      \"W_crossentropy\":1,\n",
    "      \"W_contrastive\":0,\n",
    "      \"type_of_couples\": 0,\n",
    "      \"num_of batch\" : len(train_loader),\n",
    "      \"seed\": seed,\n",
    "      \"name_saved\":'random_choice_and_frozen_layers'  \n",
    "      })\n",
    "      \n",
    "config = wandb.config\n",
    "\n",
    "# Calcola i pesi delle classi in base alle percentuali\n",
    "weight_class_0 = 1.0 / 0.7  # Peso per la classe 0\n",
    "weight_class_1 = 1.0 / 0.3  # Peso per la classe 1\n",
    "\n",
    "# Crea un tensore PyTorch con i pesi\n",
    "weight = torch.tensor([weight_class_0, weight_class_1], dtype=torch.float32).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight = weight).to(device)\n",
    "contrast_criterion = ContrastiveLoss().to(device)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate, weight_decay=config.weight_decay)\n",
    "num_epochs = config.epochs\n",
    "best_val_accuracy = 0.0 \n",
    "\n",
    "\n",
    "\n",
    "#miner = miners.MultiSimilarityMiner()\n",
    "#loss_func = losses.TripletMarginLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.2460, Train Accuracy: 0.6282, Val Loss: 1.3437, Val Accuracy: 0.7172, Val Loss unbalanced: 1.2914, Val Accuracy unbalanced: 0.5046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Train Loss: 1.2329, Train Accuracy: 0.6464, Val Loss: 1.2801, Val Accuracy: 0.7402, Val Loss unbalanced: 1.3483, Val Accuracy unbalanced: 0.4463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Train Loss: 1.2244, Train Accuracy: 0.6654, Val Loss: 1.2921, Val Accuracy: 0.7517, Val Loss unbalanced: 1.3272, Val Accuracy unbalanced: 0.4569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Train Loss: 1.2265, Train Accuracy: 0.6689, Val Loss: 1.3078, Val Accuracy: 0.7368, Val Loss unbalanced: 1.3001, Val Accuracy unbalanced: 0.4832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Train Loss: 1.2106, Train Accuracy: 0.6866, Val Loss: 1.3189, Val Accuracy: 0.7451, Val Loss unbalanced: 1.3177, Val Accuracy unbalanced: 0.4758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Train Loss: 1.2134, Train Accuracy: 0.6951, Val Loss: 1.3475, Val Accuracy: 0.7566, Val Loss unbalanced: 1.2933, Val Accuracy unbalanced: 0.4879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Train Loss: 1.2012, Train Accuracy: 0.7073, Val Loss: 1.2649, Val Accuracy: 0.7581, Val Loss unbalanced: 1.3459, Val Accuracy unbalanced: 0.4174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\Pair_model_V4.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m cluster \u001b[39m=\u001b[39m apply_randomrotations(cluster)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m#4 input data to the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m cluster_outputs_, frags_a, frags_b \u001b[39m=\u001b[39m model(cluster, positions, n_frag_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39m#5 calculate the cross entropy and the contrastive  losses\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m loss_ \u001b[39m=\u001b[39m criterion(cluster_outputs_, one_hot_labels_\u001b[39m.\u001b[39mfloat())\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\Pair_model_V4.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m cluster_subset \u001b[39m=\u001b[39m cluster_subset\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39m# apply the PCT\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m point_clouds_transformed \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mptc_net(cluster_subset)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m \u001b[39m# append the results\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m cluster_transformed \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((cluster_transformed, point_clouds_transformed), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alessandro\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\Pair_model_V4.ipynb Cell 19\u001b[0m line \u001b[0;36m9\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m feature_0 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather_local_0(new_feature)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m feature \u001b[39m=\u001b[39m feature_0\u001b[39m.\u001b[39mpermute(\u001b[39m0\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m new_xyz, new_feature \u001b[39m=\u001b[39m sample_and_group(npoint\u001b[39m=\u001b[39;49m\u001b[39m256\u001b[39;49m, nsample\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, xyz\u001b[39m=\u001b[39;49mnew_xyz, points\u001b[39m=\u001b[39;49mfeature) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=97'>98</a>\u001b[0m feature_1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgather_local_1(new_feature)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=99'>100</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpt_last(feature_1)\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\Pair_model_V4.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m B, N, C \u001b[39m=\u001b[39m xyz\u001b[39m.\u001b[39mshape\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m S \u001b[39m=\u001b[39m npoint \n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m fps_idx \u001b[39m=\u001b[39m farthest_point_sample(xyz, npoint) \u001b[39m# [B, npoint]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m new_xyz \u001b[39m=\u001b[39m index_points(xyz, fps_idx) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m new_points \u001b[39m=\u001b[39m index_points(points, fps_idx)\n",
      "\u001b[1;32mc:\\Users\\Alessandro\\Desktop\\Tesi\\PairModel\\Pair_model_V4.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     dist \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum((xyz \u001b[39m-\u001b[39m centroid) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     distance \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmin(distance, dist)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     farthest \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmax(distance, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alessandro/Desktop/Tesi/PairModel/Pair_model_V4.ipynb#X24sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mreturn\u001b[39;00m centroids\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "results_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\results'\n",
    "\n",
    "checkpoint_interval = 1  \n",
    "\n",
    "config.name_saved = 'random_choice_and_frozen_layers'\n",
    "for epoch in range(num_epochs):\n",
    "    list_of_results=[]\n",
    "    list_of_true=[]\n",
    "    \n",
    "    list_of_results_all=[]\n",
    "    list_of_true_all=[]\n",
    "\n",
    "    train_of_results=[]\n",
    "    train_of_true=[]\n",
    "\n",
    "    ######################################################################################\n",
    "    ##                                      Train                                       ##\n",
    "    ######################################################################################\n",
    "    model.train() \n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "    for batch_data in progress_bar:\n",
    "\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        # Each cluster is composed by an adjacency matrix and the cluster of fragments\n",
    "        matrix, cluster = batch_data\n",
    "        \n",
    "        #1 Let's convert the matrix into an y list and count the number of elements in the matrix\n",
    "        matrix = matrix.numpy()\n",
    "        ind=torch.triu_indices(len(matrix[0]),len(matrix[0]),offset =1)\n",
    "        y=matrix[0][ind[0],ind[1]]\n",
    "        n_frag_ = len(matrix[0])\n",
    "\n",
    "        #2 select the positions and the relative labels that represent the pairs we want to extract\n",
    "        positions, labels_ = select_couples(y,random.choice([0, 1, 2, 3]))\n",
    "       \n",
    "        num_elementi = len(positions)\n",
    "        perm_random = random.sample(range(num_elementi), num_elementi)\n",
    "        \n",
    "        positions = [positions[i] for i in perm_random]\n",
    "        labels_ = labels_[perm_random]\n",
    "        \n",
    "        labels_ = labels_.long().to(device)\n",
    "        one_hot_labels_ = F.one_hot(labels_,2)\n",
    "        train_of_true.append(labels_.tolist()) # append the true y\n",
    "\n",
    "\n",
    "        #3 apply translation to the origin and random rotations\n",
    "        cluster = apply_translation(cluster[0])\n",
    "        cluster = apply_randomrotations(cluster)\n",
    "\n",
    "        #4 input data to the model\n",
    "        cluster_outputs_, frags_a, frags_b = model(cluster, positions, n_frag_)\n",
    "        \n",
    "        #5 calculate the cross entropy and the contrastive  losses\n",
    "        loss_ = criterion(cluster_outputs_, one_hot_labels_.float())\n",
    "        contrast_loss = contrast_criterion(frags_a, frags_b, labels_)\n",
    "        loss = loss_ + config.W_contrastive*contrast_loss\n",
    "\n",
    "        #6 backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        #7 predict the y \n",
    "        _, predicted = torch.max(cluster_outputs_.data, 1)\n",
    "        train_of_results.append(predicted.tolist()) # append the predicted y\n",
    "        total_samples += one_hot_labels_.size(0)\n",
    "        correct_predictions += (predicted == labels_).sum().item()\n",
    "        progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': correct_predictions / total_samples}) # the progress bar tha shows for each cluster the live metrics\n",
    "   \n",
    "    #8 compute the metrics at the end of each epoch\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    train_loss = total_loss/len(train_loader)\n",
    "    \n",
    "    #9 log the metrics and the model of the current epoch\n",
    "    metrics_train = {\"train_loss\": train_loss, \n",
    "                       \"accuracy\": accuracy}\n",
    "    wandb.log(metrics_train)\n",
    "    \n",
    "    current_time = datetime.datetime.now()\n",
    "    checkpoint_name = f\"{current_time.strftime('%d_%m_%H%M')}_{epoch+1}_{config.name_saved}.pt\"    #################\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "\n",
    "    wandb.run.log_artifact(checkpoint_path, name=config.name_saved)\n",
    "\n",
    "\n",
    "\n",
    "    ######################################################################################\n",
    "    ##                                    Inference                                     ##\n",
    "    ######################################################################################\n",
    " \n",
    "    #                           #\n",
    "    # COPPIE BILANCIATE E FISSE #\n",
    "    #                           # \n",
    "\n",
    "    model.eval()  \n",
    "    \n",
    "    val_loss_ = 0.0\n",
    "    v_contrast_loss= 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,1)\n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            #val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "    val_metrics = {\"val_loss\": val_loss, \n",
    "                       \"val_accuracy\": val_accuracy}\n",
    "    wandb.log(val_metrics)  \n",
    "\n",
    "\n",
    "    #                  #\n",
    "    # TUTTE LE COPPIE  #\n",
    "    #                  # \n",
    "\n",
    "    model.eval()  \n",
    "    \n",
    "    val_loss_ = 0.0\n",
    "    v_contrast_loss= 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,0)\n",
    "            \n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true_all.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            #val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss_all = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results_all.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy_all = val_correct_predictions / val_total_samples\n",
    "        val_loss_all /= len(val_loader)\n",
    "    \n",
    "    all_the_values = {\"val_loss_all\": val_loss_all, \n",
    "                       \"val_accuracy_all\": val_accuracy_all}\n",
    "\n",
    "    wandb.log(all_the_values)                   \n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Loss unbalanced: {val_loss_all:.4f}, Val Accuracy unbalanced: {val_accuracy_all:.4f}')\n",
    "\n",
    "###################################################### STORE THE RESULTS ###############################################################################################################\n",
    "\n",
    "    result_path = os.path.join(results_dir, f\"VAL+_{config.name_saved}_{epoch+1}\")              #############################\n",
    "    os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(result_path, \"list_of_true.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_true, f)\n",
    "\n",
    "    with open(os.path.join(result_path, \"list_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_results, f)\n",
    "\n",
    "    train_result_path = os.path.join(results_dir, f\"TRAIN+_{config.name_saved}_{epoch+1}\")             ##################  \n",
    "    os.makedirs(train_result_path, exist_ok=True)\n",
    "\n",
    "    with open(os.path.join(train_result_path, \"train_of_true.pkl\" ), 'wb') as f:\n",
    "        pickle.dump(train_of_true, f)\n",
    "\n",
    "    with open(os.path.join(train_result_path, \"train_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(train_of_results, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferenze su modelli caricati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_stored = torch.load(r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points\\\\19_10_1209_2_random_choice_and_frozen_layers.pt') \n",
    "\n",
    "model.load_state_dict(W_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 1.2584, Train Accuracy: 0.6138, Val Loss: 1.2982, Val Accuracy: 0.7364, Val Loss unbalanced: 1.3223, Val Accuracy unbalanced: 0.4800\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,1)\n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            #val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct_predictions / val_total_samples\n",
    "        val_loss /= len(val_loader)\n",
    "    \n",
    "val_metrics = {\"val_loss\": val_loss, \n",
    "                       \"val_accuracy\": val_accuracy}\n",
    "wandb.log(val_metrics)  \n",
    "\n",
    "\n",
    "    #                  #\n",
    "    # TUTTE LE COPPIE  #\n",
    "    #                  # \n",
    "\n",
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,0)\n",
    "            \n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true_all.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            #val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss_all = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results_all.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy_all = val_correct_predictions / val_total_samples\n",
    "        val_loss_all /= len(val_loader)\n",
    "    \n",
    "all_the_values = {\"val_loss_all\": val_loss_all, \n",
    "                       \"val_accuracy_all\": val_accuracy_all}\n",
    "\n",
    "wandb.log(all_the_values)                   \n",
    "\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Loss unbalanced: {val_loss_all:.4f}, Val Accuracy unbalanced: {val_accuracy_all:.4f}')\n",
    "\n",
    "###################################################### STORE THE RESULTS ###############################################################################################################\n",
    "\n",
    "result_path = os.path.join(results_dir, f\"VAL+_{config.name_saved}_{epoch+1}\")              #############################\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(result_path, \"list_of_true.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_true, f)\n",
    "\n",
    "with open(os.path.join(result_path, \"list_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_results, f)\n",
    "\n",
    "train_result_path = os.path.join(results_dir, f\"TRAIN+_{config.name_saved}_{epoch+1}\")             ##################  \n",
    "os.makedirs(train_result_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(train_result_path, \"train_of_true.pkl\" ), 'wb') as f:\n",
    "        pickle.dump(train_of_true, f)\n",
    "\n",
    "with open(os.path.join(train_result_path, \"train_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(train_of_results, f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "list_of_results=[]\n",
    "list_of_true=[]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,0)\n",
    "            \n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            #val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss_all = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "val_accuracy_all = val_correct_predictions / val_total_samples\n",
    "val_loss_all /= len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.37622796450567536\n"
     ]
    }
   ],
   "source": [
    "print(val_accuracy_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "somma_totale = 0\n",
    "total_len = 0\n",
    "for sottolista in list_of_results:\n",
    "    somma_totale += sum(sottolista)\n",
    "    total_len +=len(sottolista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7546191825446649\n"
     ]
    }
   ],
   "source": [
    "print(somma_totale/total_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.tolist()\n",
    "# We process one cluster at a time.\n",
    "test_loader = DataLoader(test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "list_of_results_test=[]\n",
    "list_of_true_test=[]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in test_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,0)\n",
    "            \n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true_test.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss_all = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results_test.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "val_accuracy_all = val_correct_predictions / val_total_samples\n",
    "val_loss_all /= len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr><tr><td>val_accuracy</td><td>█▁</td></tr><tr><td>val_accuracy_all</td><td>▁█</td></tr><tr><td>val_loss</td><td>█▁</td></tr><tr><td>val_loss_all</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.79687</td></tr><tr><td>train_loss</td><td>0.48331</td></tr><tr><td>val_accuracy</td><td>0.76834</td></tr><tr><td>val_accuracy_all</td><td>0.55153</td></tr><tr><td>val_loss</td><td>0.51544</td></tr><tr><td>val_loss_all</td><td>1.00285</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">volcanic-dew-2</strong> at: <a href='https://wandb.ai/pair_fragments/Modello_ottimizzato/runs/9vj1dcs1' target=\"_blank\">https://wandb.ai/pair_fragments/Modello_ottimizzato/runs/9vj1dcs1</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20231018_195048-9vj1dcs1\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.5223, Train Accuracy: 0.7734, Val Loss: 285.9390, Val Accuracy: 0.7573, Val Loss unbalanced: 0.9756, Val Accuracy unbalanced: 0.5558\n"
     ]
    }
   ],
   "source": [
    "model.eval()  \n",
    "    \n",
    "val_loss_ = 0.0\n",
    "v_contrast_loss= 0.0\n",
    "val_correct_predictions = 0\n",
    "val_total_samples = 0\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "\n",
    "            val_matrix, val_cluster = val_batch\n",
    "\n",
    "            val_matrix = val_matrix.numpy()\n",
    "            ind_val=torch.triu_indices(len(val_matrix[0]),len(val_matrix[0]),offset =1)\n",
    "            y_val =val_matrix[0][ind_val[0],ind_val[1]]\n",
    "            n_frag_val = len(val_matrix[0])\n",
    "\n",
    "            # select the same number of 0 and 1 in the previous vector \n",
    "            val_positions,  val_labels_ = select_couples(y_val,0)\n",
    "            val_labels_ = torch.Tensor(val_labels_)\n",
    "            val_labels_ = val_labels_.long().to(device)\n",
    "            one_hot_labels_val_ = F.one_hot(val_labels_,2)\n",
    "            list_of_true.append(val_labels_.tolist())\n",
    "\n",
    "            val_cluster = apply_translation(val_cluster[0])\n",
    "            val_cluster = apply_randomrotations(val_cluster)\n",
    "            val_outputs_,  v_frags_a, v_frags_b = model(val_cluster,  val_positions, n_frag_val)\n",
    "            \n",
    "            val_loss_ += criterion(val_outputs_, one_hot_labels_val_.float()).item()\n",
    "            v_contrast_loss += contrast_criterion(v_frags_a, v_frags_b, val_labels_).item() \n",
    "           \n",
    "            val_loss_all = val_loss_ + config.W_contrastive*v_contrast_loss\n",
    "\n",
    "            _, val_predicted = torch.max(val_outputs_.data, 1)\n",
    "            list_of_results.append(val_predicted.tolist())\n",
    "            val_total_samples += one_hot_labels_val_.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels_).sum().item()\n",
    "\n",
    "        val_accuracy_all = val_correct_predictions / val_total_samples\n",
    "        val_loss_all  /= len(val_loader)\n",
    "\n",
    "    \n",
    "all_the_values = {\"val_loss_all\": val_loss_all, \n",
    "                       \"val_accuracy_all\": val_accuracy_all}\n",
    "\n",
    "wandb.log(all_the_values)                   \n",
    "\n",
    "print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {accuracy:.4f}, '\n",
    "          f'Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}, Val Loss unbalanced: {val_loss_all:.4f}, Val Accuracy unbalanced: {val_accuracy_all:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = os.path.join(results_dir, f\"VAL+_{config.name_saved}_{epoch+1}\")              #############################\n",
    "os.makedirs(result_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(result_path, \"list_of_true.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_true, f)\n",
    "\n",
    "with open(os.path.join(result_path, \"list_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(list_of_results, f)\n",
    "\n",
    "train_result_path = os.path.join(results_dir, f\"TRAIN+_{config.name_saved}_{epoch+1}\")             ##################  \n",
    "os.makedirs(train_result_path, exist_ok=True)\n",
    "\n",
    "with open(os.path.join(train_result_path, \"train_of_true.pkl\" ), 'wb') as f:\n",
    "        pickle.dump(train_of_true, f)\n",
    "\n",
    "with open(os.path.join(train_result_path, \"train_of_results.pkl\"), 'wb') as f:\n",
    "        pickle.dump(train_of_results, f)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
