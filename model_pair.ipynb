{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_GPU():\n",
    "    \"\"\" This function activates the gpu \n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(torch.cuda.get_device_name(0), \"is available and being used\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"GPU is not available, using CPU instead\") \n",
    "    return device  \n",
    "\n",
    "\n",
    "\n",
    "def CreateCouples(pt):\n",
    "    \n",
    "    \"\"\" This function, modifies the shape of the tensor to fit the model \n",
    "    \n",
    "    \"\"\"\n",
    "    clusters= pt.shape[0]\n",
    "    couples = []\n",
    "    # for each subcluster\n",
    "    for i in tqdm(range(0,clusters)):\n",
    "        \n",
    "        # discover the number of fragments\n",
    "        n_frags = pt[i][0].shape[0]\n",
    "\n",
    "        # exract the adj matrix\n",
    "        matr= pt[i][0]\n",
    "\n",
    "        # exract the cluster of fragments\n",
    "        data = pt[i][1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        for j in range(0,n_frags -1):\n",
    "            \n",
    "            init = j+1\n",
    "            for k in range(init,n_frags): \n",
    "\n",
    "             couples.append([data[j], data[k], matr[j][k]])\n",
    "    return couples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/qq456cvb/Point-Transformers\n",
    "\n",
    "def square_distance(src, dst):\n",
    "    \"\"\"\n",
    "    Calculate Euclid distance between each two points.\n",
    "    src^T * dst = xn * xm + yn * ym + zn * zmï¼›\n",
    "    sum(src^2, dim=-1) = xn*xn + yn*yn + zn*zn;\n",
    "    sum(dst^2, dim=-1) = xm*xm + ym*ym + zm*zm;\n",
    "    dist = (xn - xm)^2 + (yn - ym)^2 + (zn - zm)^2\n",
    "         = sum(src**2,dim=-1)+sum(dst**2,dim=-1)-2*src^T*dst\n",
    "    Input:\n",
    "        src: source points, [B, N, C]\n",
    "        dst: target points, [B, M, C]\n",
    "    Output:\n",
    "        dist: per-point square distance, [B, N, M]\n",
    "    \"\"\"\n",
    "    return torch.sum((src[:, :, None] - dst[:, None]) ** 2, dim=-1)\n",
    "\n",
    "def index_points(points, idx):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        points: input points data, [B, N, C]\n",
    "        idx: sample index data, [B, S, [K]]\n",
    "    Return:\n",
    "        new_points:, indexed points data, [B, S, [K], C]\n",
    "    \"\"\"\n",
    "    raw_size = idx.size()\n",
    "    idx = idx.reshape(raw_size[0], -1)\n",
    "    res = torch.gather(points, 1, idx[..., None].expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_size, -1)\n",
    "\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "        xyz: pointcloud data, [B, N, 3]\n",
    "        npoint: number of samples\n",
    "    Return:\n",
    "        centroids: sampled pointcloud index, [B, npoint]\n",
    "    \"\"\"\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long).to(device)\n",
    "    distance = torch.ones(B, N).to(device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long).to(device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long).to(device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        distance = torch.min(distance, dist)\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def sample_and_group(npoint, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint \n",
    "    \n",
    "    fps_idx = farthest_point_sample(xyz, npoint) # [B, npoint]\n",
    "\n",
    "    new_xyz = index_points(xyz, fps_idx) \n",
    "    new_points = index_points(points, fps_idx)\n",
    "\n",
    "    dists = square_distance(new_xyz, xyz)  # B x npoint x N\n",
    "    idx = dists.argsort()[:, :, :nsample]  # B x npoint x K\n",
    "\n",
    "    grouped_points = index_points(points, idx)\n",
    "    grouped_points_norm = grouped_points - new_points.view(B, S, 1, -1)\n",
    "    new_points = torch.cat([grouped_points_norm, new_points.view(B, S, 1, -1).repeat(1, 1, nsample, 1)], dim=-1)\n",
    "    return new_xyz, new_points\n",
    "\n",
    "\n",
    "class Local_op(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n, s, d = x.size()  # torch.Size([32, 512, 32, 6]) \n",
    "        x = x.permute(0, 1, 3, 2)\n",
    "        x = x.reshape(-1, d, s)\n",
    "        batch_size, _, N = x.size()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = torch.max(x, 2)[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = x.reshape(b, n, -1).permute(0, 2, 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class SA_Layer(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.q_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.k_conv = nn.Conv1d(channels, channels // 4, 1, bias=False)\n",
    "        self.q_conv.weight = self.k_conv.weight \n",
    "        self.v_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.trans_conv = nn.Conv1d(channels, channels, 1)\n",
    "        self.after_norm = nn.BatchNorm1d(channels)\n",
    "        self.act = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_q = self.q_conv(x).permute(0, 2, 1) # b, n, c \n",
    "        x_k = self.k_conv(x)# b, c, n        \n",
    "        x_v = self.v_conv(x)\n",
    "        energy = x_q @ x_k # b, n, n \n",
    "        attention = self.softmax(energy)\n",
    "        attention = attention / (1e-9 + attention.sum(dim=1, keepdims=True))\n",
    "        x_r = x_v @ attention # b, c, n \n",
    "        x_r = self.act(self.after_norm(self.trans_conv(x - x_r)))\n",
    "        x = x + x_r\n",
    "        return x\n",
    "    \n",
    "\n",
    "class StackedAttention(nn.Module):\n",
    "    def __init__(self, channels=256):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(channels, channels, kernel_size=1, bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(channels)\n",
    "        self.bn2 = nn.BatchNorm1d(channels)\n",
    "\n",
    "        self.sa1 = SA_Layer(channels)\n",
    "        self.sa2 = SA_Layer(channels)\n",
    "        self.sa3 = SA_Layer(channels)\n",
    "        self.sa4 = SA_Layer(channels)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # \n",
    "        # b, 3, npoint, nsample  \n",
    "        # conv2d 3 -> 128 channels 1, 1\n",
    "        # b * npoint, c, nsample \n",
    "        # permute reshape\n",
    "        batch_size, _, N = x.size()\n",
    "\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x)))\n",
    "\n",
    "        x1 = self.sa1(x)\n",
    "        x2 = self.sa2(x1)\n",
    "        x3 = self.sa3(x2)\n",
    "        x4 = self.sa4(x3)\n",
    "        \n",
    "        x = torch.cat((x1, x2, x3, x4), dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Branch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        d_points = 7 # we have 7 features for each point\n",
    "        self.conv1 = nn.Conv1d(d_points, 64, kernel_size=1, bias=False)\n",
    "        self.conv2 = nn.Conv1d(64, 64, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.gather_local_0 = Local_op(in_channels=128, out_channels=128)\n",
    "        self.gather_local_1 = Local_op(in_channels=256, out_channels=256)\n",
    "        self.pt_last = StackedAttention()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv_fuse = nn.Sequential(nn.Conv1d(1280, 1024, kernel_size=1, bias=False),\n",
    "                                   nn.BatchNorm1d(1024),\n",
    "                                   nn.LeakyReLU(negative_slope=0.2))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xyz = x[..., :3]\n",
    "        x = x.permute(0, 2, 1)\n",
    "        batch_size, _, _ = x.size()\n",
    "        x= x.double()\n",
    "        x = self.relu(self.bn1(self.conv1(x))) # B, D, N\n",
    "        x = self.relu(self.bn2(self.conv2(x))) # B, D, N\n",
    "        x = x.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=512, nsample=32, xyz=xyz, points=x)         \n",
    "        feature_0 = self.gather_local_0(new_feature)\n",
    "        feature = feature_0.permute(0, 2, 1)\n",
    "        new_xyz, new_feature = sample_and_group(npoint=256, nsample=32, xyz=new_xyz, points=feature) \n",
    "        feature_1 = self.gather_local_1(new_feature)\n",
    "        \n",
    "        x = self.pt_last(feature_1)\n",
    "        x = torch.cat([x, feature_1], dim=1)\n",
    "        x = self.conv_fuse(x)\n",
    "        x = torch.max(x, 2)[0] # Returns the maximum value of all elements in the input tensor. (2 elementes for each vector)\n",
    "        x = x.view(batch_size, -1) # Returns a new tensor with the same data as the self tensor but of a different shape.\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    \n",
    "class PairModel1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        output_channels = 2 # it's a binary classification\n",
    "\n",
    "        self.branch1 = Branch()\n",
    "        self.branch2 = Branch()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # classificator\n",
    "        self.linear1 = nn.Linear(1024, 512, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.dp1 = nn.Dropout(p=0.5)\n",
    "        self.linear2 = nn.Linear(512, 256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.dp2 = nn.Dropout(p=0.5)\n",
    "        self.linear3 = nn.Linear(256, output_channels)\n",
    "        \n",
    "    def forward(self, batch_1, batch_2):\n",
    "        \n",
    "        x_1 = self.branch1(batch_1)\n",
    "        x_2 = self.branch2(batch_2)\n",
    "\n",
    "        x = x_1 + x_2 # let's sum the output of the two branches \n",
    "\n",
    "        # classificator\n",
    "        x = self.relu(self.bn1(self.linear1(x)))\n",
    "        x = self.dp1(x)\n",
    "        x = self.relu(self.bn2(self.linear2(x)))\n",
    "        x = self.dp2(x)\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading\n",
    "train = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\train_pair_dataset_REG.pt\")\n",
    "val = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\val_pair_dataset_REG.pt\")\n",
    "#test = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\test_pair_dataset_REG.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1526/1526 [00:01<00:00, 1237.63it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 327/327 [00:00<00:00, 1162.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Change the shape of the data\n",
    "train_couples = CreateCouples(train)\n",
    "val_couples = CreateCouples(val)\n",
    "#test_couples = CreateCouples(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1713243"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_couples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's exract only some couples to make the train cycle faster\n",
    "el_1 = [[item[0], item[1],item[2]] for item in train_couples if item[2] == 1]\n",
    "el_0 = [[item[0], item[1],item[2]] for item in train_couples if item[2] == 0]\n",
    "el_0_s = el_0[0:4000]\n",
    "el_1_s = el_1[0:4000]\n",
    "\n",
    "train_list = el_1_s + el_0_s\n",
    "random.shuffle(train_list)\n",
    "\n",
    "\n",
    "\n",
    "val_1 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 1]\n",
    "val_0 = [[item[0], item[1],item[2]] for item in val_couples if item[2] == 0]\n",
    "val_0_s = val_0[0:500]\n",
    "val_1_s = val_1[0:500]\n",
    "\n",
    "val_list = val_1_s + val_0_s\n",
    "random.shuffle(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train2.pickle', 'wb') as file:\n",
    "    pickle.dump(train_list, file)\n",
    "\n",
    "with open('val2.pickle', 'wb') as file:\n",
    "    pickle.dump(val_list, file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4500 couples\n",
    "with open('train.pickle', 'rb') as file:\n",
    "    train_list = pickle.load(file)\n",
    "\n",
    "with open('val.pickle', 'rb') as file:\n",
    "    val_list = pickle.load(file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8000 couples\n",
    "with open('train2.pickle', 'rb') as file:\n",
    "    train_list = pickle.load(file)\n",
    "\n",
    "with open('val2.pickle', 'rb') as file:\n",
    "    val_list = pickle.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_list, batch_size=32)\n",
    "val_loader = DataLoader(val_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 is available and being used\n"
     ]
    }
   ],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PairModel1().to(device)\n",
    "model.double()\n",
    "\n",
    "# Sets the path where the model parameters will be stored.\n",
    "model_path_ = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\modelpair_weights.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.6735, Training Accuracy: 0.6122, Validation Loss: 0.6497, Validation Accuracy: 0.6240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Training Loss: 0.5603, Training Accuracy: 0.7129, Validation Loss: 0.6544, Validation Accuracy: 0.6170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Training Loss: 0.4979, Training Accuracy: 0.7727, Validation Loss: 0.6639, Validation Accuracy: 0.6030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Training Loss: 0.4318, Training Accuracy: 0.8109, Validation Loss: 0.6850, Validation Accuracy: 0.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Training Loss: 0.3726, Training Accuracy: 0.8547, Validation Loss: 0.7091, Validation Accuracy: 0.5930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Training Loss: 0.3192, Training Accuracy: 0.8858, Validation Loss: 0.7424, Validation Accuracy: 0.5810\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Training Loss: 0.2837, Training Accuracy: 0.8987, Validation Loss: 0.7706, Validation Accuracy: 0.5640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Training Loss: 0.2488, Training Accuracy: 0.9131, Validation Loss: 0.8258, Validation Accuracy: 0.5640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Training Loss: 0.2192, Training Accuracy: 0.9309, Validation Loss: 0.8999, Validation Accuracy: 0.5430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Training Loss: 0.1974, Training Accuracy: 0.9391, Validation Loss: 0.9660, Validation Accuracy: 0.5320\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001, weight_decay=0.001)\n",
    "num_epochs = 10\n",
    "best_val_accuracy = 0.0 \n",
    "\n",
    "checkpoint_dir = r'C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\PairModel\\\\Check_points'\n",
    "\n",
    "\n",
    "checkpoint_interval = 3\n",
    "epoch_number = 0  \n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)\n",
    "\n",
    "    ###########\n",
    "    ## Train ##\n",
    "    ###########\n",
    "\n",
    "\n",
    "    for batch_data in progress_bar:\n",
    "        optimizer.zero_grad() \n",
    "        frags_a, frags_b, labels = batch_data\n",
    "\n",
    "        frags_a = frags_a.double().to(device)\n",
    "        frags_b = frags_b.double().to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(frags_a, frags_b)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        progress_bar.set_postfix({'Loss': loss.item(), 'Accuracy': correct_predictions / total_samples})\n",
    "        \n",
    "\n",
    "    \n",
    "    accuracy = correct_predictions / total_samples\n",
    "    train_loss = total_loss/len(train_loader)\n",
    "\n",
    "\n",
    "    ###############\n",
    "    ## Inference ##\n",
    "    ###############\n",
    "\n",
    "    model.eval()  \n",
    "    \n",
    "    val_loss = 0.0\n",
    "    val_correct_predictions = 0\n",
    "    val_total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_batch in val_loader:\n",
    "            val_frags_a, val_frags_b, val_labels = val_batch\n",
    "            \n",
    "            val_frags_a = val_frags_a.double().to(device)\n",
    "            val_frags_b = val_frags_b.double().to(device)\n",
    "\n",
    "            val_labels = val_labels.to(device)\n",
    "            \n",
    "            val_outputs = model(val_frags_a, val_frags_b)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "            \n",
    "            _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "            val_total_samples += val_labels.size(0)\n",
    "            val_correct_predictions += (val_predicted == val_labels).sum().item()\n",
    "\n",
    "    val_accuracy = val_correct_predictions / val_total_samples\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {accuracy:.4f}, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), model_path_)\n",
    "\n",
    "\n",
    "\n",
    "    if (epoch + 1) % checkpoint_interval == 0:\n",
    "        \n",
    "        current_time = datetime.datetime.now()\n",
    "        checkpoint_name = f\"{current_time.strftime('%Y%m%d_%H%M%S')}_{epoch + 1}.pt\"\n",
    "\n",
    "        \n",
    "        checkpoint_path = os.path.join(checkpoint_dir, checkpoint_name)\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    epoch_number += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 327/327 [00:00<00:00, 962.06it/s]\n"
     ]
    }
   ],
   "source": [
    "test = torch.load(\"C:\\\\Users\\\\Alessandro\\\\Desktop\\\\Tesi\\\\pair_dataset\\\\dataset_1024_AB\\\\test_pair_dataset_REG.pt\")\n",
    "test_couples = CreateCouples(test)\n",
    "\n",
    "test_1 = [[item[0], item[1],item[2]] for item in test_couples if item[2] == 1]\n",
    "test_0 = [[item[0], item[1],item[2]] for item in test_couples if item[2] == 0]\n",
    "test_0_s = test_0[0:500]\n",
    "test_1_s = test_1[0:500]\n",
    "\n",
    "test_list = test_1_s + test_0_s\n",
    "random.shuffle(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_list, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4080 is available and being used\n"
     ]
    }
   ],
   "source": [
    "device=use_GPU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_stored = torch.load(model_path_)\n",
    "model.load_state_dict(W_stored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5710\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_correct_predictions = 0\n",
    "test_total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "        for test_batch in test_loader:\n",
    "            test_frags_a, test_frags_b, test_labels = test_batch\n",
    "            \n",
    "            test_frags_a = test_frags_a.double().to(device)\n",
    "            test_frags_b = test_frags_b.double().to(device)\n",
    "\n",
    "            test_labels = test_labels.to(device)\n",
    "            \n",
    "            test_outputs = model(test_frags_a, test_frags_b)\n",
    "            \n",
    "            \n",
    "            _, test_predicted = torch.max(test_outputs.data, 1)\n",
    "            test_total_samples += test_labels.size(0)\n",
    "            test_correct_predictions += (test_predicted == test_labels).sum().item()\n",
    "\n",
    "test_accuracy = test_correct_predictions / test_total_samples\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
